# Livello di collegamento
All'interno del livello di collegamento faremo riferimento al concetto di ($i$) **nodo**, ovvero un qualsiasi dispositivo ed ($ii$) al concetto di **canale di comunicazione** (o *link*), che collega nodi adiacenti.

Dov'è **implementato** il livello di collegamento? Il livello di collegamento è sostanzialmente implementato all'interno dell'hardware, in particolare all'interno della scheda di rete. Tuttavia esistono parti di esso implementate mediante software, il che indica che il livello di collegamento è una combinazione dei due.

Quali sono i **servizi offerti** dal livello di collegamento? Sebbene il servizio di base del livello di collegamento sia il trasporto di datagrammi da un nodo a quello adiacente lungo un singolo canale di comunicazione, protocolli a livello di collegamento possono includere i seguenti servizi:
- **Framing**.
I protocolli a livello di collegamento incapsulano i datagrammi provenienti dal livello di rete all'interno di una **frame**, questa costituita da un campo dati (in cui viene inserito il datagramma) ed un campo d'intestazione. Si noti che la struttura della frame varia in base al protocollo.
- **Accesso al collegamento**, attraverso cui vengono specificate le regole per immettere le frame all'interno di un canale di comunicazione.
- **Consegna affidabile**.
Abbiamo già visto che protocolli a livello di trasporto (e.g. TCP) implementano bene il servizio di consegna affidabile. Lo stesso può essere implementato all'interno del livello di collegamento per collegamenti ad elevato tasso di errore.
Questo servizio può essere spesso considerato futile per collegamenti che presentano un basso tasso di errore, come per esempio la fibra ottica o il cavo coassiale.
- **Rilevazione e correzione degli errori**.
All'interno di una frame possono talvolta verificarsi degli errori sui bit, causati dall'attenuazione di segnale o disturbi elettromagnetici.
Molti protocolli di trasporto forniscono un modo per rilevare la presenza di quest'ultimi per poi effettuarne la correzione.

## Framing dei dati
Immaginiamo di avere un canale di trasmissione come la *fibra ottica*; lo stato di questa trasmissione può essere *accesso* e *spento*, *presenza di luce* o *assenza di luce*. E' possibile, quindi, pensare di rappresentare un bit $1$ come la presenza di luce ed un bit $0$ come l'assenza di luce. Tuttavia, così facendo, non è possibile distinguere l'assenza di segnale ad una serie di bit $0$. Questo tipo di trasmissione è chiamata **trasmissione sincrona**, caratterizzata dal fatto che viene sempre trasmesso qualcosa.

Una soluzione *banale* è l'adozione di un sistema che preveda non più $2$ soli livelli, bensì **$3$ livelli**. Secondo un sistema del genere, un primo livello rappresenterebbe il bit $1$, un secondo livello l'assenza di segnale ed un terzo livello il bit $0$. Utilizzare un livello esclusivamente per indicare l'assenza di segnale indica sprecare un terzo della banda totale (i.e. *problema di ridondanza*). 

Esistono altre tecniche che permettono di *limitare la ridondanza*. Ad esempio, continuando ad usare $3$ livelli, smettiamo di associare un $bit$ ad un livello ben preciso. Secondo questo schema, un bit $1$ corrisponde al cambio di livello (in altre parole, dal secondo livello centrale mi sposto al primo livello soprastante), un bit $0$ prevede di rimanere nello stesso livello. Uno schema del genere limita le alte frequenze.

Quest'ultimo schema può essere implementato anche secondo **$5$ livelli**, in cui a meno del livello assegnato all'assenza di segnale, per ogni livello viene associato non più un $bit$ bensì una coppia di $bit$.

Un altra alternativa si basa sull'utilizzo della **codifica 4B5B**. Attraverso questa codifica, l'invio di una stringa di $4 \, bit$ prevede di aggiungere un $bit$ di *ridondanza* quindi l'invio di $5 \, bit$, calcolata attraverso una tabella prestabilita.
Secondo 4B5B, non esistono sequenze dove vi sono solo $bit$ dello stesso tipo; in altre parole, non vi sono sequenze di soli $1$ o soli $0$, motivo per cui più $0$ non può che indicare l'assenza di segnale.
All'utilizzo di 4B5B consegue il **vantaggio** di permettere l'utilizzo di un sistema a $2$ livelli ma anche lo **svantaggio** relativo ad uno spreco pari ad $\frac{1}{5}$. Per esempio, supponendo di voler trasmettere a $100 \; Mbps$, aggiungendo un $bit$ sul cavo andremo ad effettuare una comunicazione a $125 \; Mbps$, uno spreco al $25\%$ della banda totale.

Un ultima alternativa si basa sull'utilizzo della **codifica 8B10B**. Attraverso questa codifica, l'invio di una stringa di $8 \, bit$ prevede di aggiungere un $bit$ di *ridondanza* quindi l'invio di $10 \, bit$, calcolata attraverso una tabella prestabilita.
Diversamente dalla codifica 4B5B, la codifica 8B10B gode della proprietà di essere **elettricamente neutra**, il che indica che il numero di $bit \,1$ viene mantenuto il più possibile uguale al numero di bit $bit \, 0$. Questa proprietà evita che vi possa essere un *trasferimento di energia* tra un dispositivo e l'altro.
Quest'ultima codifica è utilizzata in sistemi come USB 3.0, SATA ed HDMI.
Attravero 8B10B, ogni stringa da $8 \, bit$ viene suddivisa in un primo gruppo formato da $5 \, bit$ ed un secondo formato da $3 \, bit$, i quali vengono trasformati rispettivamente in gruppi di $6 \, bit$ e $4 \, bit$.  
Concludiamo affermando che nella codifca 8B10B non vi è alcun *sbilanciamento*; casi di *squilibrio* sono possibili e vengono sistemati successivamente.

## Rilevazione e correzione degli errori
Vediamo ora tre tecniche per rilevare gli errori nei dati trasmessi: **controllo di parità** (*parity check*), per illustrare l’idea di base della rilevazione e correzione degli errori ed il **controllo a ridondanza ciclica** (*CRC*).
### Controllo di parità
La forma più semplice di controllo degli errori è il **controllo di parità**. Supponiamo che $Alice$ debba inviare un informazione $D$ formata da $d \; bit$ a $Bob$. Applicando il controllo di parità, $Alice$ sceglie il suo valore in modo da rendere pari il numero totale di $bit \; 1$ all'interno dei $d \; bit$, adesso $d + 1 \; bit$ (vale il contrario per lo schema di parità dispari).
In questo modo, l'unica operazione da svolgere per il ricevente è il conteggio dei $bit \; 1$, i quali se dispari indicano che si è verificato *almeno* un errore.

Cosa succede se il numero verificatosi è pari? In questo caso il controllo di parità non può aiutarci ma pulò farlo una sua variante bidimensionale. Quest'ultima generalizzazione del controllo di parità si basa sul disporre i $d \; bit$ da inviare a $Bob$ in una matrice composta da $i$ righe e $j$ colonne e calcolare il bit di parità per ogni riga e colonna. $Alice$, oltre ad inviare i $d \; bit$, invia a $Bob$ anche gli $i + j + 1$ *bit di parità*, i quali gli permettono di *identificare* e *correggere* il bit alterato.

### CRC
Una tecnica di rilevazione dell'errore largamente utilizzata è basata sui **codici di controllo a ridondanza ciclica** (CRC, acronimo di *cyclic redundancy check*).
I codici CRC sono anche detti **codici polinomiali**, in quanto possibile vedere la stringa di bit da inviare come un polinomio cui coefficienti sono i bit della stringa.

Secondo CRC è necessario distinguere due stringe di bit:
- $D$, composta dai $d \; bit$ da inviare;
- $G$, conosciuta come *generatore* e composta da $r + 1 \; bit$, un stringa di bit per cui si sono accordati mittente e ricevente.

> Sono stati definiti dei generatori standard di $8$, $12$, $16$ e $32 \; bit$. Lo standard CRC-32 a $32 \; bit$, in numerosi protocolli IEEE del livello di collegamento, usa il generatore: $G_{CRC-32} = 100000100110000010001110110110111$

L'idea alla base di CRC è la seguente: data una stringa $D$ (formata da $d \; bit$) da inviare, segue la scelta di $R$ (formato da $r \; bit$ addizionali). L'unione di $D$ e $R$ deve formare un numero binario esattamente divisibile per $G$. Se il ricevente nota per la divisione un resto diverso da $0$, allora egli sa che si è verificato un errore.

Tutti i calcoli di CRC sono eseguiti in aritmetica modulo $2$, il che indica che addizione e sottrazione sono operazioni uguali ed equivalenti a svolgere uno *XOR*. D'altra parte, moltiplicazioni e divisioni come in base $2$; la moltiplicazione di una stringa per $2^k$ equivale ad uno *shift a sinistra di $k$ posizioni*.
Per questo motivo, possiamo intendere $D * 2^r \; XOR \; R$ è uguale alla stringa $d + r \; bit$.

Tornando alla questione cruciale, ovvero trovare $R$ tale che $D * 2^r \; XOR \; R \; = \; nG$, ossia scegliere $R$ in modo tale da che $G$ sia divisibile per $D * 2^r \; XOR \; R$ senza resto.
Notiamo che se eseguiamo l'operazione di $XOR$ di $R$ per entrambi i membri dell'espressione otteniamo $D * 2^r \; = \; nG \; XOR \; R$. In altre parole, possiamo calcolare $R = resto \; di \; (D * 2^r \; / \; G)$

![[crc.png]]

In definitiva, CRC può rilevare errori a *burst* inferiori a $r + 1 \; bit$: ovvero tutti gli errori consecutivi di non oltre $r \; bit$ saranno rilevati.

### Distanza di Hamming
Possiamo definire la **distanza di hamming** come il numero di $bit$ diversi fra una stringa di $bit$ e l'altra. In altre parole, la distanza di hamming tra due *codeword* è uguale al numero di bit necessari per passare dall'una all'altra.
L'esempio sottostante prevede una distanza di hamming pari al numero di bit $1$ presenti all'interno del risultato all'operazione di XOR, ovvero $2$.
$$
10001100 \;\; XOR \;\; 11000100 \;\; = \;\; 01001000
$$
Un **vocabolario** per stringhe di $n \, bit$ è un sotto-insieme di tutte le possibili combinazioni, ovvero un sotto-insieme delle $2^n$ stringhe di $n \, bit$.  Possiamo definire la distanza di hamming per un vocabolario di *codeword* (i.e. stringhe di bit) come il minimo numero di $bit$ diversi fra una *codeword* e l'altra.

Come avviene la **rilevazione di un errore**? Il mittente può generare solo codeword appartenenti al vocabolario; se il canale introduce un errore, allora la rilevazione dell'errore da parte del ricevente è banale.
In particolare, il tutto si basa sulla statistica poiché possiamo affermare che la probabilità che si verifichi un errore sia molto maggiore rispetto la probabilità che si verifichino due errori e così via... 
$$P(Errori = 1) \; >> \; P(Errori = 2) \; >> \; P(Errori = 3) \; ...$$
Quindi, ipotizzando che il canale abbia introdotto un errore all'interno della codeword, possiamo supporre con forte probabilità che *la codeword inviata in origine dal mittente sia la codeword nel vocabolario con distanza di hamming minore rispetto la codeword con errore*. E' importante specificare questa probabilità poiché la correzione di un errore attraverso la distanza di hamming viene effettuata esclusivamente su base probabilistica.

Consideriamo, per esempio, un vocabolario formato dalle seguenti codeword: $000000, 000111, 111000, 111111$, un sotto-insieme delle $64$ codeword possibili. Chiaramente, la distanza di hamming fra le varie codeword è uguale a $3$ o $6$, per questo motivo possiamo definire distanza di hamming per il vocabolario pari al minimo dei due, ossia $3$.
Supponendo che al ricevente arrivi una codeword uguale a $101000$, egli può supporre con forte probabilità che la codeword inviata dal mittente fosse $111000$, codeword per cui vi è distanza di hamming minima (i.e. $2$).

A partire dall'esempio precedente, possiamo affermare che data una codeword non valida, nel caso peggiore egli avrà distanza di hamming pari ad $1$ rispetto una codeword nel vocabolario.
Inoltre, è possibile affermare che *il vocabolario che permette di correggere errori singoli all'interno di una codeword è un vocabolario con distanza uguale a $3$*.

In generale, per correggere un numero $n$ di errori all'interno di una codeword è necessario un vocabolario con distanza $d = 2n + 1$.
D'altra parte, per effettuare un rilevamente di $n$ errori all'interno di una codeword è necessario un vocabolario con distanza $d = n + 1$.

> Una codeword *illecita* (i.e. non presente all'interno del vocabolario) può avere distanza di hamming uguale ad $1$ con più codeword all'interno del vocabolario? No, poiché altrimenti la distanza per il vocabolario sarebbe uguale non più $3$ ma $2$.

A partire da una stringa di $m \, bit$ di **dati**, quanti $r \, bit$ di **ridondanza** sono necessari per correggere singoli errori? 
Supponendo stringhe di $n \, bit$, con $n = m + r$, segue un numero di codeword totali pari a $2^n$, di cui solo $2^m$ saranno *lecite*. Notiamo che a partire da una stringa di $bit$ contenuta all'interno dell'insieme di codeword lecite ($2^m$), seguono $n + 1$ possibili modi per generare codeword illecite. 
Calcolare tutte le possibili codeword illecite per ogni codeword lecita è uguale a $(n + 1) * 2^m$.
$$(n + 1) * 2^m \leq 2^n$$
$$(m + r + 1) * 2^m \leq 2^{m + r}$$
$$\frac{(m + r + 1) * 2^m}{2^m} \leq \frac{2^{m + r}}{2^m}$$
$$(m + r + 1) \leq 2^{r}$$
$$ m + 1 \leq 2^r - r$$
E' possibile costruire un diagramma rispetto tutti i possibili valori di $m$ ed $r$; è importante notare che il valore di $n = m + r$ non è mai una potenza di $2$, poiché nel momento in cui $m + 1 = 2^r - r$ allora avviene sia un incremento di $m$ che un incremento di $r$.

Trovati gli $r \, bit$ necessari a correggere errori singoli, in che modo viene stabilita la **posizione** dei bit di controllo all'interno della codeword? 
Sia data una codeword formata da $n$ bit, fissata la posizione dei bit in ordine crescente da sinistra verso destra (da $1$ verso $n$), possiamo fissare i bit di controllo come tutte quei bit cui posizione $i$ sia uguale ad una potenza di $2$; tutti gli altri bit saranno bit di dati.
<br>
<center><p><b>00</b>1<b>1</b>001<b>0</b>000</p></center>
<br>

Abbiamo capito che un bit di controllo è sempre un bit in posizione $i$, con $i$ uguale ad una potenza di $2$, ma come **stabilire il bit di controllo**? Proviamo a capirlo con il seguente esempio.
![[codici_hamming.png]]

## Protocolli di accesso multiplo
Abbiamo osservato che esistono due tipi di collegamento di rete: *punto-a-punto* e *broadcast*. Il collegamento *punto-a-punto* è sostanzialmente costituito da un trasmittente ed unico ricevente, il collegamento *broadcast* può avere più nodi trasmittenti e riceventi connessi allo stesso canale condiviso. Il termine broadcast indica che, quando un nodo trasmette una frame, il canale lo diffonde e tutti gli altri nodi ne ricevono una copia.
*Ethernet* e *Wireless LAN* sono esempi di tecnologie broadcast.

Il problema principale in un collegamento broadcast è determinare chi e quando debba parlare (i.e. trasmettere). Dato che tutti i nodi sono in grado di trasmettere frame, è possibile che due o più lo facciano nello stesso istante, per cui tutti i nodi riceveranno contemporaneamente più frame, generando una collisione e conseguentemente una perdita della frame.
*Protocolli di accesso multiplo* fissano le modalità con cui i nodi regolano le loro trasmissioni.
In generale possiamo classificare praticamente tutti i protocolli di accesso multiplo in una di queste categorie: **protocolli a suddivisione del canale**, **protocolli ad accesso casuale** e **protocolli a rotazione**.

### Protocolli a suddivisione del canale
Esistono tre tecniche per la suddivisione di un canale broadcast fra i nodi che lo condividono; dati $N$ nodi ed una velocità di $R$ bps, protocolli a suddivisione del canale sono:
- **TDM**, il quale suddivide il tempo in intervalli di tempo per poi dividere ogni intervallo in $N$ slot temporali, uno per ogni nodo. Ogni volta che un nodo ha un pacchetto da inviare, egli trasmette i bit del pacchetto durante lo slot di tempo assegnatogli. Generalmente le dimensioni dello slot sono stabilite in modo tale da permettere al più l'invio di un solo pacchetto. Una volta che tutti hanno avuto l'opportunità di parlare secondo il loro slot, la sequenza si ripete. In definitiva, TDM ha il vantaggio di evitare le collisioni ed essere imparziale, ma anche lo svantaggio di mantenere sempre ed al più un tasso trasmissivo di $R \; / \; N$ bps, anche quando vi è un solo nodo che vuole trasmettere.
- **FDM**, il quale suddivide in $N$ frequenza differenti, una per ogni nodo. Anche FDM ha il vantaggio di evitare le collisioni ed essere imparziale, tuttavia possiede anche lo svantaggio di permettere un tasso trasmissivo pari ad $R \; / \; N$ bps, anche quando vi è un solo nodo che vuole trasmettere.
- **CDMA**, terzo ed ultimo protocollo a suddivisione del canale, si basa sull'assegnare un codice ad ognuno degli $N$ nodi. Ciascun nodo utilizza il proprio codice univoco per codificare i dati inviati e, se i codici sono scelti accuratamente, viene consentito la trasmissione simultanea da parte di nodi differenti.
### Protocolli ad accesso casuale
I protocolli ad accesso casuale si basano sulla ritrasmissione di una frame ripetuta finchè questa non viene persa a causa di una collisione, quindi arriva a destinazione. La ritrasmissione non è immediata, bensì avviene dopo un periodo di tempo random.
Protocolli ad accesso casuale sono i seguenti:
- **Slotted ALOHA**, primo e più semplice protocollo di accesso casuale, si basa sulla possibilità di inviare un frame da $L \; bit$ esclusivamente all'inizio di uno slot di tempo. Infatti, il tempo è suddiviso in $L / R \; secondi$, il che equivale ad avere la possibilità di trasmettere al più una frame per ogni slot. Inoltre, se avviene una collisione allora tutti i nodi devono esserne a conoscenza prima dello scadere dello slot. I **vantaggi** di Slotted ALOHA sono: ($i$) la possibilità di trasmettere ad $R \; bps$ nel caso in cui vi sia un solo nodo attivo ed ($ii$) è fortementente *decentralizzato* poichè ciascun nodo decide in modo indipendente quando ritrasmettere la frame in caso di collisione. Tuttavia, Slotted ALOHA presenta anche i seguenti **svantaggi**:
	- Gli slot su cui si verifica una collisione vengono sprecati;
	- Poichè ogni nodo decide in modo indipendente quando ritrasmettere, alcuni slot potrebbero risultare vuoti.
	- A causa della probabilità di successo per ognuno degli $N$ nodi pari a $N * p * (1 - p)^{N-1}$, segue un efficienza massima pari al $37\%$, il che indica una velocità di trasmissione pari al più a $0,37 * R \; bps$.
- **ALOHA**, secondo cui appena una frame va in collisione, il nodo la ritrasmette immediatamente con probabilità $p$. Per determinare l'efficienza di ALOHA, notiamo che ad ogni istante esiste un nodo con probabilità $p$. Supponendo che la trasmissione di una frame $i$ inizi al tempo $t_i$, segue che affinché quest'ultima venga trasmessa con esisto positivo nessun altro nodo deve iniziare a trasmettere nell'intervallo $[ t_{(i-1)}, t_0 ]$, poichè se così fosse si verificherebbe una sovrapposizione. La probabilità che nessun nodo inizi a trasmettere a $[ t_{(i-1)}, t_0 ]$ è uguale a $(1 - p)^{N-1}$. Analogamente, nessun nodo deve trasmettere mentre la frame $i$ viene trasmessa, ovvero nell'intervallo $[ t_0, t_1 ]$, il che porta la probabilità di successo uguale a $(1 - p)^{2 * (N-1)}$.
- **CSMA**, attraverso cui si trova una soluzione ai problemi di ALOHA. I due protocolli ALOHA, infatti, prevedono che un nodo non si curi del fatto che possa esserci qualche nodo che sta trasmettendo, il che equivale ad un maleducato che continua a parlare senza preoccuparsi che altri stiano conversando tra loro. Esistono due regole per evitare questo problema:
	- *Ascoltare prima di parlare*, che nel mondo delle reti si traduce nel **rilevamento della portante**; indica di aspettare che il canale si liberi prima di inziare a trasmettere.
	- *Se qualcun altro inizia a parlare insieme a noi, noi smettiamo di parlare*, che nel mondo delle reti si traduce nel **rilevamento della collisione**; indica che se un nodo che sta trasmettendo nota una frame che interferisce con la sua, allora egli arresta la sua trasmissione, aspettando un tempo casuale prima di ritrasmettere.

	Queste due regole sono alla base dei due protocolli che studieremo: **CSMA** e **CSMA/CD** (ovvero, *CSMA con il rilevamento della collisione*).
	
	Una domanda rispetto **CSMA** è la seguente: *Se esiste rilevamento della portante, continuano ad esistere le collisioni?* 	All'istante $t_0$, il nodo $B$ rivela che il canale è inattivo, motivo per cui inizia a trasmettere. E' necessario un intervallo di tempo non nullo affinchè i bit trasmessi da $B$ si propagano sul canale. Nel frattempo, a tempo $t_1 > t_0$, il nodo $D$, che non è stato ancora raggiunto dai bit trasmessi da $B$, vuole trasmettere sul canale e, pensando che il canale sia inattivo, inizia a trasmettere i suoi bit.
	Dopo un breve periodo, la trasmissione di $B$ inizia ad interferire con quella di $D$.
	Poiché attraverso CSMA i nodi non godono della proprietà di rilevamento delle collisioni, entrambi i nodi continueranno a trasmettere l'interno frame danneggiato a causa della collisione.
	
	Cosa succede se lo **scenario** si verifica in **CSMA/CD**? Poiché attraverso CSMA/CD i nodi godono della proprietà di rilevamento delle collisioni, entrambi i nodi evitano di trasmettere l'inutile ed interno frame danneggiato a causa della collisione.
	Dopo che il primo nodo ha verificato la collisione, infatti, quest'ultimo smette di trasmettere la propria frame, aspettando un tempo *randomico* prima di ritrasmettere la frame.
	Il tempo randomico è scelto attraverso l'algoritmo di **binary exponential backoff**, per cui data l'$n-esima$ collisione durante la trasmissione, viene estratto randomicamente un valore $k$ dall'insieme ${(0, \; ..., \; 2^{n-1}) }$.	Si noti che anche *Ethernet* fa utilizzo di *binary exponential backoff*.
	
	Qual è l'**efficienza** di **CSMA/CD**? Possiamo definire l'efficienza di CSMA/CD come la frazione di tempo media durante la quale i frame sono trasferiti sul canale senza collisioni in presenza di un alto numero di nodi attivi (i.e. nodi con un'elevata quatità di frame da inviare). Il tuto può essere riassunto dalla seguente **formula**:
	$$ Efficienza \, = \, \frac{1}{1 + \frac{5 * d_{prop}}{d_{trasm}}}$$
	$d_{prop} \; =$ tempo di propagazione massimo per un segnale fra una coppia di nodi;
	$d_{trasm} \; =$ tempo necessario per trasmettere una frame della maggior dimensione possibile.
	
	- **CSMA/BA**
	...
	
	
### Protocolli a rotazione
Due proprietà auspicabili per un protocollo di accesso multiplo sono le seguenti:
- Quando vi un solo nodo che vuole trasmettere, allora vi deve essere throughput pari ad $R \; bps$.
- Quando vi sono $N$ nodi che vogliono trasmettere, allora vi deve essere throughput vicino a $R / N \; bps$.
Purtroppo, i protocolli ALOHA e CSMA possiedono la prima proprietà ma non la seconda. Dal tentativo di definire un protocollo che godesse di entrambe le proprietà, nascono i protocolli a rotazione. Noi studiamo due protocolli a rotazione, ovvero:
- Il **protocollo polling**, nel quale uno dei nodi, chiamato nodo principale, interpella a turno ogni nodo comunicandogli la possibilità di trasmettere (fino ad un massimo di frame). Un esempio di protocollo polling è *Bluetooth*. Il protocollo polling ha il vantaggio di eliminare le collisioni e gli slot vuoti, tuttavia presenta **svantaggi** come:
	- L'introduzione del ritardo per la notifica da parte del nodo principale. Se per esempio vi è un solo nodo attivo (i.e. che vuole trasmettere una frame), a causa del tempo impiegato dal nodo principale per notificare ciclicamente tutti i nodi, l'unico nodo attivo trasmette ad una velocità inferiore rispetto $R \; bps$.
	- Se vi è un guasto al nodo principale, allora l'intero canale diventa inattivo.
- Il **protocollo token-passing** (alias *token-bus*), in cui non esiste alcun nodo principale ma un messaggio di controllo (i.e. token) che circola fra i vari nodi seguendo un ordine prefissato. Se il token che riceve il token non ha frame da trasmettere allora procede all'inoltro del token verso il nodo successivo, altrimenti può trasmettere fino al numero massimo di frame trasmissibili. I problemi di token-passing sono i seguenti:
	- Il guasto di un nodo può mettere fuori servizio l'intero canale.
	- Se un nodo non riesce ad inoltrare il token, occorre invocare procedure di recupero.

## Ethernet
Ethernet, ideata negli anni $'70$ è senza dubbio la tecnlogia per LAN più diffusa, diffusione dovuto ai suoi enormi vantaggi in termini di costo, semplicità e velocità.

Cosa compone un **pacchetto Ethernet**? Un pacchetto Ethernet è composto da:
- Un **payload** (i.e. campo dati), il quale contiene il datagramma IP, che a sua volta può occupare dai $46$ ai $1500 \; byte$ (i.e. *MTU*); se il valore è maggiore rispetto il massimo numero di $byte$ allora l'host dovrà *frammentare*, se inferiore rispetto il minimo allora l'host dovrà riempire il payload con $byte$ che verranno poi scartati (i.e. *padding*).
- Un indirizzo di **destinazione**, composto da $6 \; byte$, contiene l'indirizzo **MAC** di **destinazione**.
- Un indirizzo della **sorgente**, composto da $6 \; byte$, contiene l'indirizzo **MAC** della **sorgente**.
- Un **tipo** (alias *EtherType*), composto da $2 \; byte$, permette di specificare il protocollo di rete mediante il relativo numero identificativo (e.g. $0x0806$ per ARP).
- Un controllo a ridondanza ciclica (i.e. **CRC**), composto da $4 \; byte$, consente al ricevente di rilevare e correggere un errore nei bit della frame.
- Un **preambolo**, composto da $8 \; byte$ di cui $7 \; byte$ avranno la forma $10101010$ ed $1 \; byte$ (l'ultimo) avrà la forma $10101011$. Il loro compito e far sì che la schede di rete del ricevente possa sincronizzarsi con il clock della schede di rete del trasmittente. L'ultimo byte, che differisce per gli ultimi $2 \; bit$ avvisa la scheda di rete del ricevente che stanno per arrivare "*le cose importanti*".

Si noti che l'utilizzo del preambolo è strettamente legato all'utilizzo della codifica Manchester, in modo tale da poter sincronizzare correttamente i due interlocutori. La **codifica Manchester** è una codifica utilizzata nel passaggio dal livello fisico al livello di collegamento ed basata sulla variazione di segnale; in particolare, esistono due livelli. Attraverso quest'ultima codifica, il bit $1$ viene rappresentato secondo il passaggio dall' "*alto verso il basso*"; viceversa, per quanto riguarda il bit $0$.
Per carpire bene il passaggio da un bit all'altro è necessario che mittente e ricevente siano sincronizzati: il che è possibile attraverso il preambolo.

Notiamo, inoltre, che Ethernet offre un servizio ($i$) *senza connessione*, ($ii$) *privo di handshake* e ($iii$) *poco affidabile*; tutte queste *"mancanze"* permettono ad Ethernet il suo più grande **vantaggio**, ossia l'essere semplice ed economico.

Quali e quante sono le varie **tecnologie Ethernet**? Ethernet compare in molte forme differenti e con svariate denominazioni come: $10BASE-T$, $10BASE-2$, $100BASE-T$, $1000BASE-LX$ e $10GBASE-T$.
Ogni notazione si divide in $3$ parti:
- **Velocità**, $10, 100, 1000$ o $10G$, rispettivamente per $10 \; Mbps, 100 \; Mbps, 1 \; Gbps, 10 \; Gbps$
- **Tipo di banda**, quasi sempre $BASE$, indica che il mezzo fisico trasporta solo traffico Ethernet;
- **Mezzo fisico**, come *cavi coassiali* (i.e. $5$, più spesso o $2$), *doppini in fili di rame intrecciati* (i.e. $T$) o *fibre ottiche* (i.e. $F$, $FX$ e $BX$).

Storicamente, Ethernet venne concepito con i seguenti **cablaggi**:
	- *Cavi coassiali*.
		- $10BASE5$, spesso e rigido in quanto costituito da un pezzo di rame unico non intrecciato, una guaina isolante, una calza metallica di protezione e una guaina esterna per una protezione totale. La lunghezza massima per un segmento unico è $500$ metri ma potevano essere collegati tra di loro con dei ripetitori/amplificatori di segnale (fino ad un massimo di 5 segmenti consecutivi, per una lunghezza totale uguale a $2,5km$). *Intercettare* il cavo interno era possibile attraverso una "*presa a vampiro*", la quale forava la guaina (in punti specifici) per fare contatto con la parte interna.
		- $10BASE2$, più flessibile rispetto il precedente; per estendere il cavo era sufficiente tagliare quest'ultimo ed inserire un connettore (pur rovinando il segnale). I segmenti avevano una lunghezza pari a $185$-$200 \;m$ ed era possibile unire fino a $5$ segmenti, per una lunghezza massima di $1 \; km$.
	- *Doppini in fili di rame intrecciati*.
		- $10BASET$, cui segmenti avevano grandezza pari a $100$ metri e potevano essere collegati fino a $1024$ nodi. Lo schema di collegamento infatti prevedeva un hub centrale, un concentratore ed una connessione diretta tra scheda di rete e concentratore.
	- *Fibra ottica*.
		- $10BASEF$, la quale può trasmettere fino a $2 \; km$ ed avere al più $1024$ nodi anche se in realtà la comunicazione è punto-punto come per $T$.
		
Cos'è **Fast Ethernet**? Fast Ethernet (con standard $IEEE \; 802.3u$) è un termine collettivo per indicare un numero di standard Ethernet che trasportano il traffico alla velocità di $100$ Mbps rispetto alla velocità originale Ethernet di $10$ Mbps.
**Cablaggi** relativi a Fast Ethernet sono i seguenti:
- $100BASE-T4$, una prima implementazione della Fast Ethernet. Richiede quattro coppie twisted pair. Una coppia è riservata per la *trasmissione*, una per la *ricezione* e le restanti due coppie vengono utilizzate alternativamente in una direzione o nell'altra. Ogni coppia permette una velocità pari a $33$ Mbps, il che permette a sua volta una velocità pari a $33*3$ Mbps verso una direzione (e.g. ->) e $33$ Mbps nell'altra (e.g. <-). Attraverso $100BASE-T4$ viene abbandonata la codifica Manchester ed utilizzato un codice inusuale: *8B6T*, per convertire gruppi di $8 \; bit$ in $6$ cifre in *base-3*.
- $100BASE-TX$, molto simile al precedente a meno del cavo utilizzato, il quale è CAT5. $100BASE-TX$ usa la codifica 4B5B.
- $100BASE-FX$, una versione della Fast Ethernet su fibra ottica. Usa due cavi di fibra, uno per ricevere ed uno per trasmettere. Il traffico di rete usa completamente la banda di 100 Mbps, su un segmento di fibra full duplex fino a 2 km. $100BASE-FX$ usa la codifica 4B5B.

Cos'è **Gigabit Ethernet**? Gigabit Ethernet (con standard $IEEE \; 802.3z$ su *fibra* e $IEEE \; 802.3ab$ su *rame*) è l'evoluzione a $1.000$ Mbit/s del protocollo Fast Ethernet operante a $100$ Mbit/s.
Ovviamente ottenere tale velocità è semplice con l'utilizzo della **fibra ottica** ($BASE-F$). D'altra parte, il tutto è possibile con qualche difficoltà anche con $BASE-T$.
Perché implementare sia fibra ottica che **doppini intrecciati**? Semplicemente perché ciò consente di non modificare il cablaggio relativo all'implementazione Ethernet precedente, il quale richiederebbe un costo maggiore.

Per raggiungere la velocità di $1$ Gbps a partire da $100$ Mbps è necessario eseguire i seguenti $5$ **passaggi**:
1. Rimuovere la codifica 4B5B, in questo modo passiamo da una velocità uguale a $100$ Mbps ad una velocità pari a $125$ Mbps;
2. Usare le quattro coppie disponibili simultaneamente, in questo modo passiamo da una velocità uguale a $125$ Mbps ad una velocità pari a $500$ Mbps;
3. Permettere una trasmissione full-duplex, in questo modo passiamo ad una velocità uguale a $500$ Mbps *full-duplex*;
4. Passare da $3$ a $5$ livelli per *baud*, in questo modo passiamo ad una velocità uguale a $1000$ Mbps *full-duplex*;
5. Utilizzare un FEC (acronimo di *Forward Error Connection*), in questo modo possiamo recuperare $6dB$.

> Un *baud* è la possibile variazione di segnale dallo stato precedente. Il *baud* al secondo rappresenta quante variazioni ci possono essere nell’arco di tempo. Ad ogni *baud* si può associare un solo bit oppure $2$ bit nella codifica a $5$ livelli.

Com'è certamente già notato, il primo passaggio per implementare il tutto all'interno di $BASE-T$ è rimuovere la codifica 4B5B; tuttavia, quale codifica è stata utilizzata? La codifica che è stata utilizzata è la **Codifica Trellis Viterbi**, o più semplicemente la *codifica di Viterbi*.
L’idea su cui si basa quest'ultima codifica è trasmettere $2 \; bit$ per ognuno che bit entrante, introducendo così il $100\%$ della ridondanza al fine di recuperare gli errori. 
Il tutto è possibile grazie ad un automa a stati finiti, composto da $4$ stati ($\{0,1,2,3\}$), ognuno dei quali caratterizzato da un comportamento e due frecce in uscita. L’automa è presente sia alla sorgente che alla destinazione, le quali concordano lo stato iniziale. 
In base allo stato e ciò che di vuole trasmettere, invio la determinata coppia di $bit$.
L'automa può essere talvolta rappresentato anche dal "*traliccio*" presente nella seconda figura sottostate.

![[viterbi.png]]

![[viterbi1.png]]
![[viterbi2.png]]

## Collegamenti tra LAN differenti
> Cos’è una **LAN**? Una LAN è un sistema di bus condiviso in cui possono verificarsi collisioni, ovvero il dominio di collisione. 

Relativamente a questo argomento possiamo distinguere tra vari dispositivi secondo vari livelli:
- Dispositivi di livello $1$, il livello fisico.
	- **Repeater**, un amplificatore in grado di connettere più segmenti tra loro. Un repeater dispone di due porte, una per l'entrata ed una l'uscita, le quali gli permettono di ripetere il segnale tra un segmento ed un altro, con la possibilità di introdurre errori e collisioni
	- **Hub**, un dispositivo a livello fisico con una struttura a stella a cui si collegano più nodi, utilizzato all'interno di Ethernet $10BASE-T$. Un hub può essere inteso come un concentratore in grado di riprodurre elettricamente in uscita i segnali provenienti da una coppia, senza alcun interpretazione del segnale. In altre parole, come un repeater, ha il compito di ascoltare da una porta e ripetere il segnale sulle altre collegate in uscita, con la possibilità di introdurre errori e collisioni (e.g. arrivo di due frame contemporaneamente).
- Dispositivi di livello $2$, il livello DLL.
	- **Bridge**, dispositivo che permette di trasformare le frame da un formato LAN (e.g. Ethernet) ad un altro. Attraverso un bridge, le frame provenienti dalla LAN E-H (Figura C. all'interno dell'immagine sottostante) vengono interpretate da qeust'ultimo e se necessario inoltrate verso la seconda LAN A-D.
	- **Switch**, un dispositivo intelligente con un processore, una memoria ed un firmware operativo, i quali permettono l'interpretazione del contenuto della frame Ethernet. Può essere pensato come un bridge specifico per Ethernet. Nello specifico, il compito di uno switch è analizzare l'intestazione di una frame e trovare la strada migliore per raggiungere la destinazione, preparando/utilizzando un percorso che colleghi le due macchine. Gli switch sono, infatti, dei dispositivi *plug and play*, motivo per cui non hanno bisogno di alcuna configurazione. Inizialmente, la tabella per uno switch è vuota ma acquisisce informazioni per ogni frame inviata/ricevuta. Un esempio è possibile attraverso l'immagine sottostante, in cui la macchina $A$ desidera comunicare con la macchina $H$. In questo caso la frame, arrivata allo switch $B1$ verrà inoltrata su tutte le uscite e scartata dalle macchine non interessate; in questo modo la frame arriva allo switch $B2$, la quale a sua volta inoltra su ogni collegamento fino ad arrivare a $B3$, tramite cui la frame può arrivare ad $H$. Se $H$ vuole rispondere ad $A$ con una seconda frame, allora il percorso è già conosciuto dagli switch, motivo per cui non si effettua nessun inoltro su tutte le uscite, bensì sulle sole uscite necessarie. Dopo un dato tempo in cui uno switch non riceve frame da un indirizzo, detto *Aging Time*, il determinato indirizzo viene rimosso dalla tabella. Un **problema** relativamente agli switch esiste, ed è legato alla loro topologia. Al fine di prevenire dei cicli, non possono essere costruiti dei grafi; per questo motivo utilizziamo il metodo dello **spanning tree**. *Spanning Tree Protocol* permette la costruzione di un albero a partire da un grafo ciclico; il tutto si basa sul set di un nodo root (e.g. il nodo con ID inferiore) e la definizione dei figli per ogni nodo. Ogni nodo avrà i figli necessari a rimuovere ogni ciclo nel grafo.
- Dispositivi di livello $3$, il livello di rete.
	- **Router**, un dispositivo a livello di rete; differentemente da uno switch, necessita di una configurazione.

![[dispositivi.png]]

## Indirizzamento flat vs gerarchico
Abbiamo notato che a livello di collegamento, gli indirizzi hanno un formato **flat**; il MAC Address, infatti, è scelto dalla prodotture della sceda di rete e non contiene alcuna informazione rispetto l'instradamento. Un indirizzo di rete, d'altra parte, è detto gerarchico, poiché il suo valore informa rispetto la posizione della destinazione; in altre parole, fornisce informazioni di instradamento.

L'indirizzamento flat è comodo (vantaggio), infatti, prevede che non vi siano regole di posizionamento, il che indica che l'indirizzo è fisso nell'host ed è inoltre più vantaggioso in termini di spazio di indirizzamento.
Tuttavia (svantaggio) non è possibile creare una LAN con milioni di host, poiché dispositivi come bridge e switch non sarebbero in grado di fornire i loro vantaggi; essi, infatti, imparano dalla rete, ed inizialmente necessitano di un invio in broadcast verso ogni collegamento.

In definitiva, è necessario capire bene come equilibrare bene il tutto, realizzando una struttura logica corretta raggruppando le macchine per tipologia di utenza. A partire da quest'ultimo concetto, nascono le VLAN.

## VLAN (LAN Virtuali)
Supponiamo di avere una struttura a tre piani, in cui ogni piano corrisponde ad una LAN. Attraverso una VLAN è possibile connettere macchina che si trovano su LAN differenti. Per definire una VLAN è necessario utilizzare appositi switch, i quali prevedono delle porte suddivise in gruppi; ogni gruppo costituisce una VLAN.

Quali sono i **vantaggi** di una VLAN? Il vantaggio principale di una VLAN si basa sul permettere maggiori prestazioni, dati da:
- Flessibilità, permette di spostarsi su "*piani*" diversi senza alcuna connessione a LAN diverse.
- Prestazioni, il traffico broadcast viene confinato ad utenti appartenti alla stessa VLAN;
- Sicurezza, gli utenti appartenenti a VLAN diverse non vedono i reciproci frame dati.

Possiamo distinguere due diversi tipi di VLAN:
- **untagged**, ovvero sprovviste di un tag identificativo;
- **tagged**, definite con il protocollo $802.IQ$ ed introducono un nuovo campo all'interno di una frame Ethernet: VLAN. Il nuovo campo è formato da $4 \; byte$; i primi $2 \; byte$ sono utili a specificare il protocollo VLAN, i restanti $2$ indicano ($i$) **priority**, per indicare il livello di priorità, ($ii$) **CFI**, per indicare se l'indirizzo MAC è canonico o meno ed infine ($iii$) il campo **VLANID**, il quale indica un indentificatore univoco per la VLAN.