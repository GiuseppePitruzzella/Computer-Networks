# Livello di Trasporto
## Introduzione
Un *protocollo* a livello di trasporto mette a disposizione una **comunicazione logica** tra due processi applicativi di host differenti. Con comunicazione logica intendiamo quella comunicazione che, dal punto di vista dell'applicazione, avviene come se gli host che eseguono i processi fossero direttamente connessi. Questo ovviamente non è vero, ma avviene poichè gli applicativi non si preoccupano dell'infrastruttura fisica sottostante.
I protocolli a livello di trasporto sono implementati nel sistema periferico e *non* nel router.
Come abbiamo visto in precedenza il livello di trasporto (lato mittente) converte i messaggi ricevuti in segmenti (o pacchetti a livello di trasporto).
Questo avviene spezzando se necessario il pacchetto ricevuto in parti più piccole, aggiungendo un intestazione ad ognuno di essi.
Volendo utilizzare un analogia per capire meglio il concetto di comunicazione logica, supponiamo che un gruppo di $n$ ragazzi scriva $n$ lettere ad un'altro gruppo di $n$ ragazzi. I due gruppi abitano in due case diverse ed in due città diverse.
Un ragazzo per gruppo ha il compito di inviare o ritirare le lettere e distribuirle.
In questo caso il servizio postale fornisce comunicazione logica tra le due case mentre il ragazzo $A$ ed il ragazzo $B$ provvedono alla comunicazione logica tra i due gruppi di ragazzi.
Possiamo intendere quindi i messaggi dell'applicazione come le lettere nelle buste, i processi come i ragazzi, gli host come i condomini che abitano le rispettive case, il protocollo a livello di trasporto come $A$ e $B$, mentre il protocollo a livello di rete come il servizio postale (compresi di postini).
### Panoramica del livello di trasporto
Internet, e più in generale una rete TCP/IP, mette a disposizione del livello applicativo due diversi protocolli: 
- **UDP**, che fornisce un servizio non affidabile e non orientato alla connessione.
- **TCP**, che fornisce un servizio affidabile ed orientato alla connessione, il che lo rende per ovvii motivi più complesso del precedente.
Uno sviluppatore sceglie tra i due durante la creazione della socket. Anche se ne parleremo meglio nei prossimi capitoli, facciamo un breve cenno ai protocolli a livello di rete.
Sappiamo che un pacchetto a livello di rete è chiamato *datagramma* e che il protocollo utilizzato a livello di rete è **IP**.
Il modello di IP si basa sul *best effort* (i.e. massimo sforzo), il che indica che farà del suo meglio ma comunque non fornisce alcuna garanzia sulla consegna dei segmenti che gli arrivano; in altre parole, non assicura che arriveranno a destinazione o nel giusto ordine, per questo motivo si dice che IP offre un servizio non affidabile.
Il principale compito di TCP ed UDP è quindi estendere il servizio fornito da IP. In particolare per trasformarlo da consegna tra due sistemi periferici a consegna tra processi in esecuzione su sistemi periferici.
Questo passaggio descritto sopra, anche chiamato da host-to-host a process-to-process, viene detto multiplexing e demultiplexing a livello di trasporto.

## Multiplexing e demultiplexing
Nell'host destinatario il livello di trasporto ha il compito di consegnare i dati dei segmenti al processo appropriato.
Ricordiamo che un processo può gestire una o più socket, attraverso le quali i dati fluiscono dalla rete al processo e viceversa.
Il livello di trasporto, quindi, non invia i dati direttamente al processo bensì alla **socket**.
Ad ognuna di queste socket è associato un *identificatore univoco*, con un formato dipendente dal protocollo scelto (i.e. TCP o UDP).

Definiamo il **demultiplexing** come il compito di trasportare i segmenti verso la giusta socket, mentre il multiplexing come il compito, svolto dal *mittente*, di radunare dati da diverse socket e incapsulare ognuno di questi con intestazioni per creare dei segmenti e passarli al livello di rete.
Richiamando l'**analogia** precedente, diciamo che il ragazzo $A$ effettua un *operazione di multiplexing* quando raccoglie le lettere per poi spedirle, mentre il ragazzo $B$ effettua un *operazione di demultiplexing* quando leggendo il nome consegna la lettera al corretto destinatario.

Il multiplexing quindi richiede ($i$) che le socket abbiano un identificatore univoco e ($ii$) che ciascun segmento presenti campi che indichino la socket a cui va consegnato il segmento. I campi a cui facciamo riferimento sono ($i$) il campo del numero di *porta di origine* ed ($ii$) il campo del numero di *porta di destinazione*.
In definitiva, possiamo affermare che ogni socket nell'host deve avere un *numero di porta*, in modo tale che quando un segmento arriva all'host, il livello di trasporto possa dirigere il segmento alla socket corrispondente. Infine la socket consegnerà i dati al processo.

### Numeri di porta
I **numeri di porta** sono numeri di $16 \; bit$ che vanno da $0$ a $65535$.
- Porte da $0$ a $1023$ sono chiamati numeri di porta noti (well-known port number)
- Porte da $1024$ a $49151$ sono chiamate numeri di porta registrati (registered ports)
- Porte da $49152$ a $65535$ sono porte dinamiche o private.

## UDP
Il primo protocollo di trasporto che studiamo è **UDP**, un protocollo che svolge fa il *lavoro minimo* che un protocollo di trasporto debba fare; svolge la funzione di **multiplexing** / **demultiplexing** ed una forma di **controllo degli errori** molto semplice.

In particolare, il lavoro svolto da UDP è prendere i messaggi dal processo applicativo, aggiungere il *numero di porta di origine* e di *destinazione* per il *multiplexing/demultiplexing*, per poi aggiungere altri $2$ piccoli *campi* e passare il tutto al livello di rete. Chiaramente, non esiste *handshaking*, il che rende UDP un protocollo *non orientato alla connessione*. 
Un **esempio** di protocollo applicatico che utilizza UDP è **DNS**.

Quali sono i motivi per preferire UDP rispetto a TCP?
- **Controllo più fine a livello applicativo**;
UDP per la sua natura permette impacchettare e trasferire al livello sottostante i dati ricevuti con tempi inferiori rispetto TCP, il quale non curante dei tempi richiesti, ritarda l'invio dei pacchetti dati i suoi meccanismi di controllo di congestione ed invia segmenti finchè non viene notificata la ricezione per quest'ultima. UDP è per questo motivo preferibile all'interno di applicativi in tempo reale, quali non permettono eccessivi ritardi ma permettono la perdita di un pacchetto.
- **Nessuno stato di connessione**;
TCP include uno stato della connessione nei sistemi periferici, il che include buffer di ricezione ed invio, parametri per il controllo della congestione, sul numero di sequenza e di ACK.
 UDP, d'altra parte, non conserva lo stato della connessione e non tiene traccia di quest'ultimi parametri. Per questo motivo, un server può generalmente supportare più client attivi quando l'applicazione utilizza UDP rispetto a TCP.
- **Minor spazio utilizzato per l'intestazione del pacchetto**, poiché l'intestazione dei pacchetti TCP aggiunge 20 byte, UDP solo 8.

> Si noti che anche se UDP nasce senza alcun servizio di trasporto affidabile, quest'ultimo servizio può essere fornito se presente nell'applicazione stessa (per esempio con meccanismi di notifica). Un esempio è QUIC (Quick UDP Internet Connection) utilizzato dal browser Chrome. 

### Struttura dei segmenti di UDP
La struttura di un **segmento UDP** si basa sui seguenti **campi**:
- **Numeri di porta**, di origine e destinazione (entrambi da $16$ bit), necessari per effettuare *multiplexing* / *demultiplexing*.
- **Campo lunghezza**, formato da $16$ bit, presenta il numero di byte del segmento UDP (*intestazione* + *dati*).
- **Checksum**, formato da $16$ bit, per verificare se vi sono errori nei bit che formano il segmento, quindi in altre parole che non siano stati alterati durante il trasferimento. Nel lato mittente il campo checksum viene riempito con il complemento a uno della somma di tutte le parola di memoria da $16$ bit nel segmento (l'eventuale riporto finale viene sommato al primo bit). Ricordiamo che il complemento a uno si effettua convertendo i bit $0$ in $1$ e viceversa. Nel lato ricevente invece verrà effettuata la somma delle parole di memoria più il campo checksum. Se non ci sono errori (rappresentati da bit $0$) il risultato dovrà essere formato da soli bit $1$. In caso di errori, alcune implementazioni di UDP si limitano a scartare il segmento danneggiato, altre lo trasmettono all'applicazione con un avvertimento.
- **Campo dati**, formato da $32$ bit, ossia la parte che contiene il messaggio di richiesta o di risposta.
Il campo di intestazione di UDP, è formato da 4 campi da 2 byte ciascuno.

## Il trasferimento affidabile
Un canale affidabile implica che nessun bit è corrotto o va perduto, per cui tutti i bit sono consegnati nell'ordine di invio.
In questo paragrafo vedremo come sviluppare un trasferimento affidabile per mittente e ricevente, utilizzando modelli di macchine a stati finiti via via più complesse.
Assumeremo quindi che i pacchetti vengano consegnati nel giusto ordine, ma vi sia la possibilita che vengano persi.
Utilizzeremo chiamate come `rdt_send()` (con `rdt` acronimo di *Reliable Data Transfer*) per indicare il trasferimento di dati da parte del mittente, `rdt_rcv()` quando il pacchetto raggiunge il ricevente e `deliver_data()` per inviare i dati al livello superiore. Consideriamo, inoltre, un trasferimento dati unidirezionale poichè un trasferimento dati bidirezionale sarebbe più noioso in termini di spiegazione.
### RDT 1.0
Iniziamo la trattazione di $RDT$ con $RDT \; 1.0$, il quale ci mostra la soluzione più semplice e banale per il trasferimento affidabile su un canale affidabile, il tutto attraverso $2 \; FSM$ (i.e. *macchina a stati finiti*), una per il mittente ed una per il destinatario.
- **Mittente**
	1. `rdt_send(data)` -> Evento che causa la transizione. Crea un pacchetto contenente i dati ricevuti dal livello superiore grazie alla chiamata `make_pkt(data)`; in seguito, lo invia sul canale attraverso `udt_send(packet)`.
- **Ricevente**
	1. `rdt_rcv(packet)` -> Evento che causa la transizione; prevede che i pacchetti vengano raccolti dal livello sottostante ed i dati estratti dal pacchetto attraverso `extract(packet, data)`. I dati vengono poi passati al livello superiore secondo `deliver_data()`.

All'interno di RDT \; 1.0 tutti i pacchetti fluiscono dal mittente verso il ricevente poiché per ipotesi disponiamo di un *canale perfettamente affidabile*, il che implica che nulla possa andare storto.

> Usiamo la lettera "$\Lambda$" a destra o sinistra della freccia se rispettivamente l'evento non causa alcuna transizione o viceversa una transizione si verifica senza il determinarsi di un evento.

### RDT 2.0
Un modello più *realistico* riguarda la possibilità che i bit possano essere corrotti, errore che può verificarsi quando il pacchetto viene trasmesso, inserito nel buffer o ritrasmesso.
Analizziamo una piccola analogia. All'interno di una chiamata e per ogni frase, i due interlocutori al telefono potrebbero scambiarsi dei "messaggi" di notifica come "*OK*" ($ACK$), per intendere che la frase è stata compresa oppure "*Ripeti*" ($NAK$) se la frase non è stata compresa.
Nell'ambito delle reti di calcolatori, protocolli basati sul *ritrasferimento* sono chiamati protocolli *ARQ*.
Protocolli ARQ gestiscono il rilevamento di errori con $3$ funzionalità aggiuntive:
- **Rilevamento dell'errore**, un meccanismo in grado di rilevare gli errori sui bit. Ricordiamo che UDP utilizza per questo il campo checksum.
- **Feedback del destinatario**, ovvero le risposta di notifica positiva ($ACK$) o negativa ($NAK$). Tali pacchetti di notifica potrebbero essere costituiti da un solo bit, per esempio $0$ per NAK ed $1$ per ACK.
- **Ritrasmissione**, in quanto un pacchetto con errori sarà ritrasmesso dal mittente.

Le tre funzionalità descritte predentemente compongono $RDT 2.0$, il quale è formato dalle seguenti $2 \; FSM$:
- **Mittente**
	1. `rdt_send(data)` -> Una volta ricevuti i dati dal livello sopra, viene creato il pacchetto insieme al checksum per poi inviare il tutto. In seguito si passa al secondo stato sottostante.
	2. Attesa di $ACK$ o $NAK$ -> Il mittente resta in attesa di una notifica da parte del ricevente, il quale se $NAK$ comporterà la ritrasmissione dell'ultimo pacchetto ed il ritorno nel *secondo stato*, quindi l'attesa di una nuova notifica; se $ACK$ avviene il passaggio al *primo stato*, in quanto egli saprà che il pacchetto spedito più di recente è stato ricevuto senza alcun problema. Si noti che finché il mittente si trova nel secondo stato egli sarà impossibilitato ad inviare nuovi pacchetti, il che rende il protocollo $RDT \; 2.0$ ed analoghi dei protocolli $stop-and-wait$.
- **Ricevente**
	1. `rdt_rcv(packet)` && `corrupt(packet)` -> Ricevuto un pacchetto da parte del mittente, allora se quest'ultimo è corrotto (`corrupt(packet)`) allora viene creato ed inviato un pacchetto contenente $NAK$.
	2. `rdt_rcv(packet)` && `not_corrupt(packet)` -> Ricevuto un pacchetto da parte del mittente, allora se quest'ultimo non è corrotto (`not_corrupt(packet)`) allora vengono estratti i dati al suo interno per poi inviare quest'ultimi al livello superiore, quindi viene creato ed inviato un pacchetto contenente $ACK$.

### RDT 2.1
Se $RDT \; 2.0$ sembra funzionare bene, in realtà così non è; dimentichiamo che anche $ACK$ o $NAK$ potrebbero essere corrotti. Risolviamo questo problema attraverso $RDT \; 2.1$.
Considerando l'**analogia** basata sulla telefonata, notiamo che la risposta "*OK*" o "*Ripeti*"" da parte di $A$ possa non esser stata capita, per cui segue la domanda di $B$: "*Che cos'hai detto?*" a cui a sua volte potrebbe succedere un "Che cos'hai detto tu?" da parte di $A$ e così via...
Per risolvere il problema andiamo ad aggiungere un numero identificativo ai pacchetti. Questo numero identificativo avrà valore $0$ o $1$. Il mittente invia il primo pacchetto con numero identificativo $0$ e si mette in attesa di un $ACK$ da parte del ricevente. Il ricevente invierà un $ACK$ e si metterà in attesa del pacchetto $1$ o un $NAK$ se riceve un pacchetto corrotto. Il mittente, se riceve una risposta corrotta o se riceve un $NAK$ reinvia il pacchetto, se riceve un ACK va ad inviare il pacchetto $1$. Potrebbe capitare che la risposta corrotta sia un $ACK$, in questo caso, quando il ricevente riceve nuovamente un pacchetto con il codice precedente reinvierà l'$ACK$ per il pacchetto precedente. In questo modo il mittente si risincronizzerà e potranno continuare con la comunicazione.

### RDT 2.2
All'interno di $RDT \; 2.2$, il destinatario, per segnalare al mittente di aver ricevuto un pacchetto corrotto, spedisce un $ACK$ per l’ultimo pacchetto ricevuto correttamente, invece di inviare un segnale $NAK$. Così facendo il mittente che riceve due $ACK$ per lo stesso pacchetto($ACK$ duplicati) sa che il destinatario non ha ricevuto quello successivo e quindi lo ritrasmette.

### RDT 3.0
Supponiamo che il canale oltre a danneggiare i bit possa anche **perdere pacchetti**. Soluzione è in questo caso quella di utilizzare un **timer**: il *mittente* inizializza un *contatore* ogni volta che invia un pacchetto, motivo per cui se non riceve un $ACK$ per quel pacchetto prima che il timer termini allora egli ritrasmette quest'ultimo. Stimare il tempo da settare per un timer è molto difficile in quanto non si può mai avere la certezza che questo sia abbastanza *grande* da non introdurre troppi pacchetti duplicati ed abbastanza *piccolo* da non perdere troppo tempo prima di ritrasmetterlo. $RDT \; 3.0$ introduce un *timer* e le primitive ad esso associate al fine di gestire la *perdita di pacchetti*.

### Pipelining
RDT 3.0 risulta corretto dal punto di vista dell'affidabilità, tuttavia è inefficiente relativamente alle prestazioni. A causare le cattive prestazioni di quest'ultimo è la strategia da egli utilizzata: *stop and wait*, per cui il mittente non può spedire il pacchetto $i + 1$ se non ha prima ricevuto un $ACK$ per il pacchetto $i$.

Una soluzione si basa sull'applicazione del metodo **pipelining**, per cui è possibile inviare pacchetti senza aspettare l'$ACK$ per il pacchetto precedente da parte del ricevente (e.g. se il mittente invia $3$ pacchetti alla volta senza aspettare l'$ACK$, implica triplicare il *throughput*).

E' possibile *implementare il pipelining* attraverso: **Go-Back-N** e **Ripetizione Selettiva**.

#### Go-Back-N (GBN)
Una prima implementazione del pipelining si basa su **Go-Back-N**, il quale permette al mittente di poter inviare più pacchetti senza rimanere in attesa di un $ACK$; tuttavia, il numero di pacchetti inviati dal mittente che non hanno ancora ricevuto un $ACK$ non può essere maggiore di $N$.

All'interno della *pipeline*, possiamo distinguere $4$ diversi segmenti (i.e. *intervalli*). Possiamo definire `base` come l'indice del pacchetto più vecchio ed ancora senza $ACK$, mentre `nextseqnum` come l'indice del prossimo pacchetto da inviare al destinatario. Gli intervalli sono i seguenti:
- $(0, base - 1)$, formato da tutti i pacchetti inviati che hanno ricevuto un $ACK$ da parte del ricevente.
- $(base, nextseqnum - 1)$, formato da tutti i pacchetti inviati che *non* hanno ricevuto un $ACK$ da parte del ricevente.
- $(nextseqnum, base + N - 1)$, formato da tutti i pacchetti che possono essere ancora inviati al ricevente.
- $(base + N, ...)$, formato da tutti i pacchetti che *non* possono essere inviati al ricevente se il mittente non riceve prima un ACK per un pacchetto all'interno dell'intervallo $(base, nextseqnum - 1)$.

Per questo motivo, $N$ è spesso chiamata ampiezza della finestra ed il protocollo **GBN** definito **protocollo a finestra scorrevole**.
![[gobackn.png]]
Per concludere, denotiamo le caratteristiche di mittente e destinatario GBN descritti attraverso le rispettive *FSM*. Un **mittente GBN** deve rispondere a $3$ tipi di evento:
- *Invocazione dall'alto*, per cui se vengono ricevuti dati dal livello soprastante, egli crea ed invia il pacchetto se e solo se la finestra non è piena, ovvero non vi sono già $N$ pacchetti in attesa di $ACK$. Se la finestra è piena, i dati ricevuti vengono ritornati al livello soprastante, il quale riprova più tardi.
- *Ricezione di un $ACK$*, il quale viene definito **cumulativo** ed indica che un $ACK$ per il pacchetto $n$ implichi la corretta ricezione di tutti i pacchetti con indice minore di $n$.
- *Evento di timeout*, che nel caso in cui si verifichi prevede che il mittente invii nuovamente tutti i pacchetti spediti che non hanno ancora ricevuto un $ACK$. Se il mittente riceve un $ACK$ ed esistono ancora pacchetti in $(base, nextseqnum - 1)$, il timer viene fatto ripartire. Altrimenti, se dopo la ricezione di un ACK non esistono più pacchetti in $(base, nextseqnum - 1)$, il timer viene stoppato.

D'altra parte, le azioni del destinatario sono le seguenti: 
- Se un pacchetto con un indice $n$ viene ricevuto correttamente ed in ordine (ossia l'ultimo pacchetto ricevuto possedeva indice $n-1$), allora il destinatario invia un $ACK$ per il pacchetto con indice $n$.
- In tutti gli altri casi, il destinatario *scarta il pacchetto* ed invia al mittente un $ACK$ per l'ultimo pacchetto ricevuto correttamente. Ciò accade banalmente anche se un pacchetto è stato ricevuto correttamente ma non è in ordine. Il motivo è il seguente: pur ipotizzando che il pacchetto $i + 1$ (*non in ordine*) venga conservato in attesa del pacchetto $i$, se il pacchetto $i$ viene perso durante la trasmissione, allora GBN impone di rispedire sia $i$ che $i + 1$ (i.e. da $i$ in poi). Conseguentemente, il destinatario può scartare il pacchetto non in ordine a fronte di una maggiore semplicità d'uso.

> L'operazione di ritrasmissione può risultare dispendiosa, tuttavia permette al destinatario di conservare il solo numero di sequenza successivo per il prossimo pacchetto.

#### Ripetizione Selettiva
Il problema di GBN esiste nel momento in cui l'ampiezza della finestra è abbastanza grande da dover rispedire una quantità ingente di pacchetti nel caso in cui uno di essi viene perduto.
Un protocollo a **ripetizione selettiva** risolve quest'ultimo problema considerando una finestra in cui possono esistere pacchetti che hanno ricevuto e che non hanno ricevuto l'$ACK$.
In questo senso, il destinatario che riceve un pacchetto non in ordine, invia un $ACK$ al mittente e mantiene quest'ultimo in un buffer finché non sono stati ricevuti i pacchetti mancanti. In altre parole, il ricevente invia al livello soprastante il tutto (il pacchetto ricevuto più i pacchetti nel buffer) se ha ricevuto fino al pacchetto `rcv_base`, ossia il primo pacchetto non in ordine.
D'altra parte, la finestra del mittente scorre esclusivamente nel caso in cui venga ricevuto un $ACK$ per il pacchetto inviato meno di recente ed ancora in attesa dI $ACK$.

## TCP
**TCP** è il protocollo di Internet a livello di trasporto. TCP gode delle seguenti **caratteristiche**:
- E' **orientato alla connessione**, in quanto prima di effettuare lo scambio dei dati, i processi effettuano un *handshake*: una serie di segmenti utili a stabilire i parametri per il trasferimento dei dati. In particolare, parliamo di un *handshake a tre vie*, così definito poiché tre sono i segmenti necessari ad instaurare una connessione tra client e server.
- E' in **esecuzione** all'interno delle due macchine periferiche e non negli elementi intermedi come router e switch.
- Offre un servizio **full-duplex**, motivo per cui i dati tra $2$ host, per esempio $Alice$ e $Bob$, possono fluire da $Alice$ verso $Bob$ ed allo stesso tempo da $Bob$ verso $Alice$.
- Offre un servizio **punto-punto**, motivo per cui è possibile un trasferimento tra un singolo mittente ed un singolo destinatario.
- *Non* offre un servizio **multicast**, motivo per cui il trasferimento da un mittente verso più destinatari non è possibile.

Come viene stabilita una **connessione** tra $2$ host secondo TCP? Come abbiamo già scritto, instaurare una connessione prevede un handshake a tre vie, il quale si compone di ($i$) una richiesta di connessione del client verso il server, ($ii$) una conseguente risposta dal server e ($iii$) un terzo ed ultimo segmento può trasportare payload. Una votla concluso l'handshake, client e server possono scambiarsi dati provenienti dal livello applicativo.

Come avviene il **trasferimento** dei dati su una connessione TCP tra $2$ host? Instaurata una connessione è possibile l'invio dei dati, motivo per cui il processo client può inviare un flusso di dati attraverso la socket, il quale può essere intesa come il punto di contatto tra il processo ed il protocollo a livello di trasporto. Non appena i dati sono nella mani di TCP, egli dirige i dati al **buffer di invio**, all'interno del quale saranno conservati finché TCP non li preleva per inviarli. Secondo un RFC, TCP afferma di prelevare i dati dal buffer "*quando è più conveniente*". 
Quando i dati vengono ricevuti da parte del destinatario, quest'ultimi vengono memorizzati all'interno del **buffer di ricezione**, da cui può leggere il processo applicativo.

Qual è la **massima quantità di dati** posizionabile e prelevabile nel buffer di invio? La quantità massima di dati, talvolta definita come dimesione massima di segmento (i.e *MSS*), è impostata considerando la relativa intestazione e sopratutto la lunghezza massima per una frame (i.e. *MTU*); per questo motivo, dato l'utilizzo di Ethernet (con $MTU = 1500 \; byte$) ed un intestazione normalmente pari a $40 \; byte$, segue un $MSS = 1460 \; byte$.
E' importante notare che MSS non è la massima dimensione di un segmento TCP, bensì la massima quantità di dati proveniente dal processo applicativo posta all'interno del segmento TCP (payload).

Com'è formato un **segmento TCP**? Un segmento TCP è formato dalla seguente struttura:
- **Numero di porta di origine**, un campo formato da $16 \; bit$;
- **Numero di porta di destinazione**, un campo formato da $16 \; bit$;
- **Numero di sequenza** per il determinato segmento, un campo formato da $32 \; bit$ ed utilizzato da mittente e destinatario per implementare il trasferimento affidabile. Più nello specifico, il numero di sequenza per un dato segmento può essere inteso come l'indice del byte all'interno del flusso di byte. In altre parole, ipotizziamo un flusso di byte da inviare da $Alice$ verso $Bob$ uguale a $500 \, 000 \; byte$, con un $MSS=1000\;byte$ ed il primo byte del flusso sia numerato con $0$; segue che il primo segmento avrà numero di sequenza uguale a $0$, il secondo uguale a $1000$, il terzo $2000$ e così via.
- **Numero di $ACK$**, un campo formato da $32 \; bit$ ed utilizzato da mittente e destinatario per implementare il trasferimento affidabile;
- **Campo finestra di ricezione**, un campo formato da $16 \; bit$ ed utilizzato per il controllo di flusso (il numero di byte che il destinatario è disposto ad accettare). Il controllo di flusso è un servizio utile affinché il mittente non saturi il buffer del destinatario;
- **Campo lunghezza dell'intestazione**, un campo formato da $16 \; bit$ ed utilizzato per specificare la lunghezza dell'intestazione TCP, la quale possiede lunghezza variabile a causa del campo di opzioni.
- **Campo checksum**, un campo formato da $16 \; bit$;
- **Campo opzioni**, un campo formato da lunghezza variabile ed utilizzato in modo facoltativo da mittente e destinatario per concordare alcuni parametri per il trasferimento dei dati;
- **Campo flag**, un campo formato da $6 \; bit$ e formato a sua volta dai seguenti bit:
	- **ACK**, utilizzato per indicare che il valore trasportato nel *campo di ACK* è valido, ossia che il segmento contiene un ACK per un segmento che è stato ricevuto con successo.
	- **RST**, **FIN** e **SYN**, utilizzati per impostare e chiudere la connessione;
	- **PSH**, se pur quasi mai utilizzato, se $1$ indica che il destinatario dovrebbe inviare immediamente i dati appena ricevuti al livello superiore;
	- **URG**, se pur quasi mai utilizzato, indica che nel segmento esistono dati "*urgenti*"
- **Campo puntatore a dati urgenti**, un campo formato da $16 \; bit$, il quale punta all'ultimo byte di dati urgenti.

Come reagisce TCP alle possibile **perdite di pacchetti**? Per far fronte alle possibili perdite di pacchetti, TCP fa uso di un **timer**. Definito **RTT** come il tempo che intercorre tra l'invio del segmento e la ricezione del suo ACK, è facile notare che il valore del timer per TCP deve essere maggiore di RTT.

Com'è possibile **stimare** il valore di **RTT**? Il valore di RTT, denotato $SampleRTT$, viene valutato esclusivamente per un solo pacchetto degli $n$ pacchetti inviati per cui non si è ancora ricevuto $ACK$ (non appartenenti all'insieme di pacchetti da ritrasmettere), il che indica approsimativamente il calcolo di $SampleRTT$ ad ogni RTT. I valori RTT possono variare ad ogni calcolo, motivo per cui TCP effettua una stima di quest'ultimi, calcolando una *media ponderata* uguale ad $EstimatedRTT = (1 - \alpha) * EstimatedRTT + \alpha * SampleRTT$. Si noti che la $EstimatedRTT$ attribuisce maggiore importanza ai campione recenti rispetto i campioni passati. Quest'ultima media ponderata è meglio definita con il nome di **EWMA** (acronimo di *Exponentially Weighted Moving Average*), una media pesata esponenziale mobile.
Oltre ad avere una stima di RTT, è anche importante possedere la misura della sua variabilità; per questo motivo, possiamo definire $DevRTT = (1 - \beta) * DevRTT + \beta * (SampleRTT - EstimatedRTT)$. Si noti che $DevRTT$ non è altro che un EWMA della differenza tra $SampleRTT$ ed $EstimatedRTT$; inoltre, minori saranno le *fluttuazioni*, minore sarà il valore di $DevRTT$.

Come viene calcolato il valore per il timer in TCP? Abbiamo notato esistere un legame tra il timer ed i vari parametri legati a loro volta al concetto di RTT. Possiamo affermare che il valore per il timer, denotato $TimeoutInverval$, è uguale al tempo medio per $RTT$ più un certo margine moltiplicato per il numero di fluttuazioni. In simboli matematici, $TimeoutInverval = EstimatedRTT + 4 * DevRTT$.

TCP utilizza un solo timer, anche in presenza di  riavvia il timer ogni qual volta riceve un $ACK$ ed esistono ancora dei pacchetti in attesa di $ACK$. In caso di *timeout* del timer, il pacchetto viene ritrasmesso e conseguentemente viene riavviato il timer.
> E' importante notare che, secondo un $RFC$, il valore iniziale per il timer è uguale ad $1\,s$. In caso di *timeout* del timer, il valore del timer viene raddoppiato per poi essere aggiornato (secondo la formula vista) alla ricezione del prossimo segmento.

Quali sono gli **eventi principali** all'interno di TCP? Esistono 3 eventi principali all'interno di TCP:
- **Arrivo di dati dal livello applicativo**, per cui TCP incapsula i dati all'interno di un segmento e lo passa ad IP. Se non esiste già un segmento in attesa di $ACK$, quindi il timer non è in funzione, allora quest'ultimo viene attivato per il segmento appena passato ad IP. E' utile pensare che il timer sia legato al segmento in attesa di $ACK$ inviato più nel passato.
- **Timeout per il timer**, per cui TCP ritrasmette il segmento che lo ha causato, riavviando poi il timer;
- **Ricezione di un ACK**, ossia l'arrivo di un segmento di $ACK$ con un valore $y$ valido nel campo $ACK$. In questo caso, TCP confronta il valore $y$ con la sua variabile $SendBase$. Ricordiamo che $SendBase$ è l'indice per il pacchetto inviato più nel passato ed ancora in attesa di $ACK$. Poiché TCP utilizza $ACK$ cumulativi, il valore $y$ conferma la ricezione di tutto ciò che è precedente ad esso. Pertanto, se il valore $y$ è maggiore o uguale di $SendBase$, allora l'$ACK$ si riferisce ad uno o più segmenti che non avevano ancora ricevuto conferma. Il mittente, quindi, aggiorna la variabile $SendBase$.

**TCP è un protocollo GBN o SR**? TCP può essere inteso come un ibrido tra i protocolli di tipo GBN ed SR.
Ricordiamo che gli $ACK$ TCP sono cumulativi e che i segmenti ricevuti correttamente, ma in modo disordinato, non vengono notificati singolarmente dal destinatario. Quindi, il mittente TCP deve solo memorizzare il numero di sequenza più basso tra i byte trasmessi che non hanno ancora ricevuto acknowledgment ($SendBase$) e il numero di sequenza del successivo byte da inviare ($NextSeqNum$). In questo senso, TCP somiglia molto a un protocollo di tipo GBN.
Tuttavia, esistono delle differenze tra TCP e GBN. Supponiamo che il mittente invii $0, \, ..., \, N$ segmenti al destinatario, i quali arrivano in ordine e senza errori; il destinatario risponde con degli $ACK$ per i segmenti da $0, \, ..., \, n - 1$, finché un $ACK$ per un segmento $n < N$ viene perso. In questo scenario, il protocollo GBN ritrasmetterebbe tutti i pacchetti da $n$ ad $N$. TCP, invece, ritrasmette al più il segmento $n$; TCP, inoltre, potrebbe addirittura non ritrasmettere alcun segmento se l'$ACK$ per il segmento $n + 1$ arriva al mittente prima del timeout del timer.
Una modifica proposta per TCP è il *riscontro selettivo*, per cui il destinatario può inviare un $ACK$ selettivo per i segmenti non in ordine, piuttosto che uno cumulativo per l'ultimo segmento senza errori ed in ordine.
Il riscontro selettivo e la scelta nativa di TCP di non ritrasmettere tutti i segmenti da $n$ ad $N$ nel caso dello scenario precedente, rendono quest'ultimo simile anche ad un generico protocollo SR.
In definitiva e come detto inizialmente, TCP può essere inteso come un ibrido tra i protocolli di tipo GBN ed SR.

Cos'è la **ritrasmissione rapida** in TCP? Uno dei problemi legati alle ritrasmissioni di pacchetti è relativo al periodo di timeout del timer, il quale può rivelarsi relativamente lungo. Fortunatamente, il mittente può rilevare la perdita ancor prima che scada il timer: attraverso gli **$ACK$ duplicati**.
Quando TCP riceve un segmento non in ordine, ovvero con numero di sequenza maggiore rispetto a quello aspettato, rileva un segmento mancante nel flusso; per questo motivo, il destinatario invia un $ACK$ relativo all'ultimo segmento ricevuto in ordine, duplicando così l'$ACK$ per un segmento.
Si noti che TCP invia un $ACK$ duplicato per ogni pacchetto ricevuto non in ordine, motivo per cui se il mittente invia $0, 1, 2, 3$ segmenti ma il destinatario riceve $0$, e poi $2$ e $3$, allora egli invia l'$ACK$ per $0$ per poi inviare due volte l'$ACK$ per il segmento $1$.

Cos'è il **controllo di flusso**? Il controllo di flusso è uno dei servizi offerti da TCP, utile ad evitare che il mittente saturi il buffer del destinatario. Si basa banalmente sul confronto tra la velocità di invio da parte del mittente e la velocità di lettura dei dati da parte del ricevente. L'implementazione del servizio di controllo di flusso è possibile mediante una variabile conservata dal mittente: la **finestra di ricezione**, utile a mostrare al mittente lo spazio libero all'interno del buffer del destinatario. Chiaramente, essendo TCP un protocollo *full-duplex*, questa variabile è conservata da entrambi gli host nella connessione.
Supponendo l'invio di un file di grande dimensioni da $Alice$ verso $Bob$.
- $Bob$ alloca un buffer di ricezione per la connessione, cui dimensione è denotata con $RcvBuffer$ e legge ogni tanto dal buffer.
$Bob$ tiene traccia di due variabili: ($i$) $LastByteRead$, uguale all'ultimo byte letto da $Bob$, ($ii$) $LastByteRcvd$, uguale all'ultimo byte copiato nel buffer di $Bob$.
Chiaramente, poiché è possibile mandare in overflow il buffer di $Bob$, la dimensione del buffer $RcvBuffer$ deve essere maggiore o uguale alla differenza tra i byte ricevuti (i.e. $LastByteRcvd$) ed i byte letti (i.e. $LastByteRead$).
Definiamo la variabile finestra di ricezione con il parametro $rwnd = RcvBuffer - (LastByteRcvd - LastByteRead)$. $Bob$ comunica $rwnd$ ad $Alice$ scrivendo il suo valore all'interno del campo apposito del segmento. Inizialmente il valore di $rwnd$ è uguale ad $RcvBuffer$.
- $Alice$, d'altra parte, tiene traccia di due variabili: ($i$) $LastByteSent$, uguale all'ultimo byte inviato a $Bob$, ($ii$) $LastByteAcked$, uguale all'ultimo byte per cui si è ricevuto $ACK$ da $Bob$. Possiamo calcolare il numero di bytes senza $ACK$ inviati da $Alice$ attraverso $NoAckedBytes = LastByteSent - LastByteAcked$.

Se il numero di bytes senza $ACK$, $NoAckedBytes = LastByteSent - LastByteAcked$, viene mantenuto minore o uguale rispetto la variabile finestra di ricezione (i.e. $NoAckedBytes \leq rwnd$) allora non vi è pericolo di *overflow* per il buffer di $Bob$ da parte di $Alice$.

Supponiamo che ad un certo tempo $i$, il buffer di $Bob$ sia pieno. Supponiamo, quindi, che ad un certo tempo $i + 1$, $Alice$ comunichi (mediante ACK per un segmento) che si è liberato dello spazio all'interno del buffer. Cosa succede se l'ACK per il segmento comunicante lo spazio libero viene perso? Chiaramente i due interlocutori risulterebbero bloccati.
Per risolvere quest'ultimo problema, TCP utilizza un secondo timer: **Persistent Timer**, il quale scatta nel momento in cui $rwnd = 0$, ovvero il buffer del destinatario è pieno. Al timeout del timer, il mittente invia un messaggio di sveglia al ricevente; se quest'ultimo non risponde al messaggio, la connessione viene chiusa.

Per evitare che il mittente possa inviare bytes non appena riconosce il minimo "*spiraglio*" nel buffer, la **soluzione di Clark** prevede che il destinatario non comunichi subito la variabile finestra di ricezione nel caso in cui si sia liberato poco spazio.

> E' importante non confondere il controllo di congestione con il controllo di flusso. Infatti, entrambi, per motivi diversi, causano un rallentamento al mittente ma il primo avviene a causa di ritardi dovuti al traffico nella rete.

Cos'è l'**algoritmo di Nagle**? Ad un certo tempo si pensò fosse una pratica inefficiente quella in cui fosse possibile inviare segmenti anche e solo per un singolo byte (e.g. Telnet). Per evitare ciò, Nagle propose l'algoritmo omonimo.
L'algoritmo di Nagle afferma che, dopo aver inviato un segmento a tempo $i$, posso inviare un segmento a tempo $i + 1$ se: ($i$) esiste un quantitativo $x$ di dati che devono essere inviati verso il destinatario, ($ii$) esiste $rwnd > MSS$, quindi lo spazio libero all'interno del buffer del destinatario è maggiore rispetto la dimensione massima per il payload nel segmento e ($iii$) esiste $x > MSS$, ovvero il numero $x$ di byte da inviare è maggiore di quelli inseribili all'interno del segmento. Se una di queste condizioni non è rispettata, il mittente ha tempo di accumulare dati finché non arriva l'$ACK$ per il segmento inviato a tempo $i$.
L'algoritmo di Nagle permette di sfruttare al meglio un segmento, migliorando le prestazioni del sistema; d'altra parte, l'utilizzo dell'algoritmo prevede un decremento dell'interattività per il sistema.

Come viene **stabilità una connessione** TCP? Oppure, come avviene l'**handshake a tre vie** in TCP? Supponiamo che un processo in un host (client) voglia inizializzare una connessione con un altro processo in un altro host (server). Inizialmente, il processo client comunica con il lato client TCP, il quale a sua volta instaura una connessione TCP con il server mediante i seguenti passi:
1. Invia un segmento speciale al TCP lato server. Questo primo segmento speciale è chiamato **segmento SYN** ed è caratterizzato da: ($i$) nessun payload, ($ii$) bit $SYN = 1$ e ($iii$) campo numero di sequenza uguale ad un valore $ClientSeqNum$ generato più o meno casualmente.
2. Il server riceve il segmento SYN, motivo per cui alloca il buffer e le variabili per la connessione. In seguito, risponde al client con un segmento speciale: un **segmento SYNACK**, caratterizzato da: ($i$) nessun payload, ($ii$) bit $SYN = 1$, ($iii$) $ACK = ClientSeqNum + 1$ e ($iv$) un campo numero di sequenza uguale ad un valore $ServerSeqNum$ scelto dal server stesso.
3. Il client riceve il segmento SYNACK, motivo per cui alloca il buffer e le variabili per la connessione. In seguito, risponde al server con un terzo ed ultimo segmento speciale, caratterizzato da: ($i$) possibilità di contenere payload, ($ii$) bit $SYN = 0$, ($iii$) $ACK = ServerSeqNum + 1$.

Come viene **terminata una connessione** TCP? Una connessione tra due host può essere stabilità e talvolta può essere anche terminata. Entrambi gli interlocutori hanno la possibiltà di chiudere la connessione. 
Supponiamo che l'host client voglia chiudere la connessione con il server. Fare ciò è possibile mediante i seguenti passi:
1. Il client invia al server un segmento speciale caratterizzato dal bit $FIN = 1$.
2. Il server riceve il segmento speciale e spedisce il proprio segmento speciale caratterizzato anch'esso da bit $FIN = 1$.
3. Il client riceve il segmento speciale da parte del server e risponde con un $ACK$ verso il server.

Terminare la connessione implica la deallocazione di buffer e variabili per entrambi gli interlocutori.
E' importante notare che la chiusura della connessione è **unidirezionale**, diversamente all’apertura che è invece *bidirezionale*. E' possibile, quindi, chiudere la connessione da $Alice$ verso $Bob$ ma tenere aperta la connessione da $Bob$ verso $Alice$. Se il client chiude la connessione verso il server, il server può continuare ad inviare dati verso il client, ottenendo i relativi $ACK$ ma mai dei dati. 
Esiste, inoltre, la possibilità che $Alice$ pensi che la connessione sia ancora aperta in modo bidirezionale mentre $Bob$ pensa che è aperta in modo unidirezionale verso di egli; ciò avviene se il segmento $FIN$ di $Bob$, che vuole terminare la connessione, viene perso.

Cos'è il **controllo di congestione**? Possiamo definire la congestione di rete come il tentativo da parte di troppe sorgenti di inviare dati a ritmi troppo elevati, motivo per cui possiamo definire il controllo di congestione come un metodo per adeguare l'attività dei mittenti in relazione al traffico.
TCP utilizza un controllo di congestione **end-to-end**; infatti, il livello IP non offre alcun supporto riguardo il controllo di congestione, motivo per cui TCP deve necessariamente utilizzare un approccio end-to-end ed essere in grado di individuare la congestione attraverso la perdita di segmenti, alle quali consegue il decremento dell'ampiezza della propria finestra.
TCP consiste nell’imporre a ciascun mittente un **limite alla velocità di invio** sulla propria connessione in funzione della congestione di rete percepita. Se il mittente TCP si accorge di condizioni di *scarso traffico* sul percorso che porta alla destinazione, incrementa il proprio tasso trasmissivo; se, invece, percepisce traffico lungo il percorso, lo riduce. Tale approccio solleva tre domande:
- Come può il mittente TCP **limitare la velocità** di invio del traffico sulla propria connessione? TCP è in grado di ridurre la velocità di invio del traffico sulla connessione attraverso l'aggiunta di una variabile per gli interlocutori: la finestra di congestione (i.e. `cwnd`). Nello specifico la quantità di dati che non hanno ancora ricevuto $ACK$ non può essere inferiore al minimo tra `cwnd` ed `rwnd`. $NoAckedBytes = LastByteSend - LastByteAcked \leq min\{cwnd, rwnd\}$.
- Come **percepisce** la **congestione** sul percorso che porta alla **destinazione**? TCP è in grado di individuare la congestione attraverso la perdita di segmenti, ovvero l'occorrenza di un timeout o la ricezione di $3$ $ACK$ duplicati da parte del destinatario. Si noti che TCP considera gli $ACK$ come indicazione che i segmenti sono arrivati con successo motivo per cui in base alla frequenza con cui arrivano al mittente, egli decide in che misura ampliare la finestra di congestione. In altre parole, più alta è la frequenza con cui arrivano gli $ACK$ e con più rapidità verrà ampliata la finestra di congestione. Poiché TCP utilizza gli $ACK$ per "*temporizzare*" gli incrementi per la finestra di congestione, possiamo affermare che TCP sia **auto-temporizzato**.
- Quale **algoritmo** dovrebbe essere usato dal mittente per variare la velocità di invio in funzione della congestione end-to-end? Il celebrato **algoritmo di controllo di congestione di TCP** si basa su $3$ **componenti** principali:
	- **Slow start**, componente obbligatoria per i mittenti TCP. Quando si stabilisce una connessione TCP, il valore di `cwnd` viene in genere inizializzato a $1 \; MSS$, il che comporta una velocità di invio iniziale di circa $MSS/RTT$. . Dato che la banda disponibile alla connessione può essere molto più grande di $MSS/RTT$, durante la fase iniziale, detta **slow start**, il valore di cwnd parte da $1$ MSS e si incrementa di $1 \; MSS$ ogni volta che un segmento trasmesso riceve un $ACK$. Questo processo ha come effetto il raddoppio della velocità trasmissiva a ogni RTT. Quindi, in TCP, la velocità di trasmissione parte lentamente, ma cresce in modo *esponenziale* durante la fase di slow start. Tuttavia, quando termina la crescita esponenziale, ovvero la fase di slow start? Slow start può terminare in $3$ modi: 
		1. Nel caso in cui vi sia un timeout, motivo per cui `cwnd` viene posto ad $1$ ed una nuova variabile di stato `ssthresh` uguale a $cwnd/2$. Successivamente a questo evento, inizia un nuovo processo di slow start.
		2. Nel caso in cui, per evitare di raggiungere nuovamente una velocità per cui è nata in precedenza congestione, `cwnd` è uguale ad `ssthresh`. Successivamente a questo evento, TCP entra nella fase *congestion avoidance*.
		3. Nel caso in cui vengono rilevati $3$ $ACK$ duplicati. Successivamente a questo evento, TCP opera una *ritrasmissione rapida* ed entra nello stato di *fast recovery*.
	- **Congestion Avoidance**, componente obbligatoria per i mittenti TCP. Come abbiamo già scritto, TCP entra nello stato di congestion avoidance per evitare di raggiungere nuovamente una velocità per cui è nata in precedenza congestione, motivo per cui adotta un approccio più conservativo nell'incremento di `cwnd`, incrementando quest'ultimo di $1$ MSS per ogni RTT. Questa operazione di incremento può essere implementata attraverso un incremento di `cwnd` di $MSS * (MSS/cwnd)$ per ogni $ACK$. Quando **termina** congestion avoidance? Questa seconda fase, che prevede un incremento lineare di `cwnd`, termina in $2$ modi:
		- Nel caso in cui vi sia un timeout, motivo per cui `cwnd` viene posto ad $1$ ed `ssthresh` uguale a $cwnd/2$. Successivamente a questo evento, inizia un nuovo processo di slow start.
		- Nel caso in cui vengono rilevati $3$ $ACK$ duplicati, motivo per cui `cwnd` viene posto ad $cwnd/2$ ed `ssthresh` uguale a $cwnd/2$. Successivamente a questo evento, TCP entra nello stato di *fast recovery*.
	- **Fast recovery**, componente suggerita ma non obbligatoria per i mittenti TCP. In questa terza ed ultima fase, il valore di `cwnd` è incrementato di $1$ MSS per $ACK$ relativo al segmento perso. Se vengono rilevati $3$ $ACK$ duplicati nella fase di fast recovery, allora il valore di `cwnd` viene decrementato per poi eseguire una transizione a *congestion avoidance*. Se si verifica un **timeout** nella fase di fast recovery, allora dopo aver impostato il valore di `cwnd` ad $1$ ed `ssthresh` uguale a $cwnd/2$, viene effettuata una transizione verso *slow start*. E' importante notare che la fase di fast recovery è consigliata ma non obbligatoria, motivo per cui una prima versione di TCP, ossia **TCP Tahoe**, non faceva uso di quest'ultima fase. **Tahoe**, infatti, impostava `cwnd` ad $1$ ed entrava in slow start per ogni evento di perdita. D'altra parte, la versione più recente di TCP, ossia **TCP Reno**, adotta fast recovery. **Tahoe** e **Reno**, al dì fuori dell'adozione di fast recovery, hanno comportamento abbastanza simile; tuttavia, nel caso in cui vengano inizializzate $2$ comunicazione TCP all'interno dello stesso canale di comunicazione, allora Reno è in grado occupare più banda rispetto Tahoe.

L'algoritmo di controllo di congestione di TCP precedentemente descritto è spesso indicato come **incremento additivo, decremento moltiplicativo** (**AIMD**, acronimo di *additive-increase multiplicative-decrease*)

> L’algoritmo Vegas tenta di evitare la congestione mantenendo allo stesso tempo un buon throughput. L’idea alla base di Vegas è ($i$) rilevare la congestione nei router tra origine e destinazione prima che si verifichi un evento di perdita e ($ii$) abbassare la velocità in modo lineare quando si profila l’imminente perdita di un pacchetto.
